{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-learning-lab-osokin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data"
      ],
      "metadata": {
        "id": "mRSx49CQuWBD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UYGk1Q67dX0S"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q idx2numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/deep_learning_lab_osokin.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mVp4VRIwVRZC",
        "outputId": "7d5ddc2a-212a-4003-b7ac-e688ad6d5bbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern u'/content/deep_learning_lab_osokin.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb) to various other\n",
            "formats.\n",
            "\n",
            "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "-------\n",
            "\n",
            "Arguments that take values are actually convenience aliases to full\n",
            "Configurables, whose aliases are listed on the help line. For more information\n",
            "on full configurables, see '--help-all'.\n",
            "\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "    This mode is ideal for generating code-free reports.\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "    relevant when converting to notebook format)\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "    overwriting the existing notebook.\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "--generate-config\n",
            "    generate default config file\n",
            "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
            "    Default: 4\n",
            "    Choices: [1, 2, 3, 4]\n",
            "    The nbformat version to write. Use this to downgrade notebooks.\n",
            "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
            "    Default: ''\n",
            "    Directory to write output(s) to. Defaults to output to the directory of each\n",
            "    notebook. To recover previous default behaviour (outputting to the current\n",
            "    working directory) use . as the flag value.\n",
            "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
            "    Default: 'FilesWriter'\n",
            "    Writer class used to write the  results of the conversion\n",
            "--log-level=<Enum> (Application.log_level)\n",
            "    Default: 30\n",
            "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
            "    Set the log level by value or name.\n",
            "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
            "    Default: u''\n",
            "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\n",
            "    but can be any url pointing to a copy  of reveal.js.\n",
            "    For speaker notes to work, this must be a relative path to a local  copy of\n",
            "    reveal.js: e.g., \"reveal.js\".\n",
            "    If a relative path is given, it must be a subdirectory of the current\n",
            "    directory (from which the server is run).\n",
            "    See the usage documentation\n",
            "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\n",
            "    slideshow) for more details.\n",
            "--to=<Unicode> (NbConvertApp.export_format)\n",
            "    Default: 'html'\n",
            "    The export format to be used, either one of the built-in formats\n",
            "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\n",
            "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\n",
            "    the import path for an `Exporter` class\n",
            "--template=<Unicode> (TemplateExporter.template_file)\n",
            "    Default: u''\n",
            "    Name of the template file to use\n",
            "--output=<Unicode> (NbConvertApp.output_base)\n",
            "    Default: ''\n",
            "    overwrite base name use for output files. can only be used when converting\n",
            "    one notebook at a time.\n",
            "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
            "    Default: u''\n",
            "    PostProcessor class used to write the results of the conversion\n",
            "--config=<Unicode> (JupyterApp.config_file)\n",
            "    Default: u''\n",
            "    Full path of a config file.\n",
            "\n",
            "To see all available configurables, use `--help-all`\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb\n",
            "    \n",
            "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "    \n",
            "    You can specify the export format with `--to`.\n",
            "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "    \n",
            "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "    \n",
            "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "    can specify the flavor of the format used.\n",
            "    \n",
            "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "    \n",
            "    You can also pipe the output to stdout, rather than a file\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "    \n",
            "    PDF is generated via latex\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "    \n",
            "    You can get (and serve) a Reveal.js-powered slideshow\n",
            "    \n",
            "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "    \n",
            "    Multiple notebooks can be given at the command line in a couple of \n",
            "    different ways:\n",
            "    \n",
            "    > jupyter nbconvert notebook*.ipynb\n",
            "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "    \n",
            "    or you can specify the notebooks list in a config file, containing::\n",
            "    \n",
            "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "    \n",
            "    > jupyter nbconvert --config mycfg.py\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9f0c6928788b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jupyter nbconvert --to html /content/deep_learning_lab_osokin.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'jupyter nbconvert --to html /content/deep_learning_lab_osokin.ipynb' returned non-zero exit status 255."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import idx2numpy\n",
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "from scipy.special import softmax as sf"
      ],
      "metadata": {
        "id": "3ScLcttCv4hq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_P_NkdPwnuO",
        "outputId": "0c7666bc-3d84-4140-8e4d-0ef580d93d3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/2021_deep-learning/'\n",
        "%ls -l ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYiopD3UwqJ0",
        "outputId": "c433ad93-2d72-4727-fa76-6c3f4a4a086c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/2021_deep-learning\n",
            "total 22648\n",
            "-rw------- 1 root root 1648877 Dec 13 21:59 't10k-images-idx3-ubyte (1).gz'\n",
            "-rw------- 1 root root 1648877 Dec 14 11:47  t10k-images-idx3-ubyte.gz\n",
            "-rw------- 1 root root    4542 Dec 13 21:59 't10k-labels-idx1-ubyte (1).gz'\n",
            "-rw------- 1 root root    4542 Dec 14 11:47  t10k-labels-idx1-ubyte.gz\n",
            "-rw------- 1 root root 9912422 Dec 13 21:47 'train-images-idx3-ubyte (1).gz'\n",
            "-rw------- 1 root root 9912422 Dec 14 11:47  train-images-idx3-ubyte.gz\n",
            "-rw------- 1 root root   28881 Dec 13 21:58 'train-labels-idx1-ubyte (1).gz'\n",
            "-rw------- 1 root root   28881 Dec 14 11:47  train-labels-idx1-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN = 300\n",
        "OUTPUT = 10\n",
        "CLASS_COUNT = 10\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCH_COUNT = 20\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "C99ZSfJQW37w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(file):\n",
        "    with gzip.open(file, 'r') as f:\n",
        "        _ = int.from_bytes(f.read(4), 'big')\n",
        "        image_count = int.from_bytes(f.read(4), 'big')\n",
        "        row_count = int.from_bytes(f.read(4), 'big')\n",
        "        column_count = int.from_bytes(f.read(4), 'big')\n",
        "        image_data = f.read()\n",
        "        return np.frombuffer(image_data, dtype=np.uint8).reshape((image_count, \n",
        "                                                                  row_count, \n",
        "                                                                  column_count))"
      ],
      "metadata": {
        "id": "R8t42095u6Y7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(file):\n",
        "    with gzip.open(file, 'r') as f:\n",
        "        _, _, label_data = int.from_bytes(f.read(4), 'big'), int.from_bytes(f.read(4), 'big'), f.read()\n",
        "        return np.frombuffer(label_data, dtype=np.uint8)"
      ],
      "metadata": {
        "id": "0yHDnjUciTfX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(a, CLASS_COUNT):\n",
        "    return np.squeeze(np.eye(CLASS_COUNT)[a.reshape(-1)])"
      ],
      "metadata": {
        "id": "CcgTR7hdiUit"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = load_images('train-images-idx3-ubyte.gz') / 255.0\n",
        "x_test = load_images('t10k-images-idx3-ubyte.gz') / 255.0\n",
        "y_train = one_hot(load_labels('train-labels-idx1-ubyte.gz'), CLASS_COUNT)\n",
        "y_test = one_hot(load_labels('t10k-labels-idx1-ubyte.gz'), CLASS_COUNT)\n",
        "x_train = x_tr.reshape((x_tr.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))"
      ],
      "metadata": {
        "id": "pLYKRhchvCCm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Definition"
      ],
      "metadata": {
        "id": "sEYRUncouk96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(network, x_train, y_pred, y_true):\n",
        "    dz1 = y_pred - y_true\n",
        "    dz0 = np.matmul(dz1, network.w[1].T) * network.derivative_relu(network.t)\n",
        "\n",
        "    mc = 1.0 / x_train.shape[0]\n",
        "    network.w[1] = network.w[1] - network.lr * mc * np.matmul(network.h.T, dz1)\n",
        "    network.b[1] = network.b[1] - network.lr * mc * np.sum(dz1, axis=0)\n",
        "    network.w[0] = network.w[0] - network.lr * mc * np.matmul(x_train.T, dz0)\n",
        "    network.b[0] = network.b[0] - network.lr * mc * np.sum(dz0, axis=0)"
      ],
      "metadata": {
        "id": "V6O1qtEWhdXR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(network, x):\n",
        "    x = np.matmul(x, network.w[0]) + network.b[0]\n",
        "    network.t = x.copy()\n",
        "    x = network.relu(x)\n",
        "    network.h = x.copy()\n",
        "    x = np.matmul(x, network.w[1]) + network.b[1]\n",
        "    x = network.softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "INy7m_oPhelY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class networkImpl(object):\n",
        "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
        "        super(networkImpl, self).__init__()\n",
        "        self.input_layer = input_layer\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.output_layer = output_layer\n",
        "        self.w = [np.random.normal(0, np.sqrt(2 / input_layer), \n",
        "                                  (input_layer, hidden_layer)),\n",
        "                  np.random.normal(0, np.sqrt(2 / (input_layer + output_layer)), \n",
        "                                  (hidden_layer, output_layer))]\n",
        "        self.b = [np.full(hidden_layer, 0.05),\n",
        "                  np.full(output_layer, 0.05)]\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(x, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_true, y_pred):\n",
        "        return np.mean(-np.sum(y_true * np.log(y_pred), axis=1))\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(y_true, y_pred):\n",
        "        return np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative_relu(x):\n",
        "        return np.where(x > 0.0, 1, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        return sf(x, axis=1)"
      ],
      "metadata": {
        "id": "YKTezaAjwBdW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = networkImpl(input_layer=x_train.shape[1], hidden_layer=HIDDEN, output_layer=OUTPUT)"
      ],
      "metadata": {
        "id": "XfqPRqAHXoPC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self, x_train, y_train, validation_data=None, epochs=10, learning_rate=0.1, batch_size=64):\n",
        "        self.lr = learning_rate\n",
        "        print(\"------- Network train -------\")\n",
        "        started = datetime.now()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            t_epoch_started = datetime.now()\n",
        "\n",
        "            for i in range(x_train.shape[0] // batch_size + np.sign(x_train.shape[0] % batch_size)):\n",
        "                st = i * batch_size\n",
        "                ed = min((i + 1) * batch_size, y_train.shape[0])\n",
        "                y_pred = forward(self, x_train[st:ed])\n",
        "                backward(self, x_train[st:ed], y_pred, y_train[st:ed])\n",
        "\n",
        "            epoch_time = (datetime.now() - t_epoch_started).total_seconds()\n",
        "            y_pred = forward(self, x_train)\n",
        "            loss = self.cross_entropy_loss(y_train, y_pred)\n",
        "            accuracy = self.accuracy(y_train, y_pred)\n",
        "            print(\"EPOCH \", epoch+1, \"| EPOCH_TIME=\", epoch_time, \" LOSS=\", loss, \" ACCURACY=\" , accuracy)\n",
        "\n",
        "        print(\"SUMMARY_TIME=\", (datetime.now() - started).total_seconds(), \" s\")\n",
        "        print(\"------- Network test -------\")\n",
        "        y_pred = forward(self, validation_data[0])\n",
        "        loss = self.cross_entropy_loss(validation_data[1], y_pred)\n",
        "        accuracy = self.accuracy(validation_data[1], y_pred)\n",
        "        print(\"LOSS=\", loss, \" ACCURACY =\", accuracy)"
      ],
      "metadata": {
        "id": "fZVsGC8ZnvAp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "QfPSgyd7upR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(network, x_train[:], y_train[:], validation_data=(x_test, y_test), epochs=EPOCH_COUNT, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ZD5J-QNewUJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a61828-e39b-4633-affd-ffec98e2e025"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- Network train -------\n",
            "EPOCH  1 | EPOCH_TIME= 8.269415  LOSS= 0.00797397834177622  ACCURACY= 0.9987333333333334\n",
            "EPOCH  2 | EPOCH_TIME= 8.134783  LOSS= 0.007514832174634876  ACCURACY= 0.99875\n",
            "EPOCH  3 | EPOCH_TIME= 8.338087  LOSS= 0.006339637358216156  ACCURACY= 0.9992333333333333\n",
            "EPOCH  4 | EPOCH_TIME= 8.283425  LOSS= 0.005771929333740817  ACCURACY= 0.9994\n",
            "EPOCH  5 | EPOCH_TIME= 9.040358  LOSS= 0.005195996862634612  ACCURACY= 0.9995666666666667\n",
            "EPOCH  6 | EPOCH_TIME= 8.598364  LOSS= 0.004647724026514128  ACCURACY= 0.9996833333333334\n",
            "EPOCH  7 | EPOCH_TIME= 8.29081  LOSS= 0.004250302958910789  ACCURACY= 0.9997333333333334\n",
            "EPOCH  8 | EPOCH_TIME= 8.288345  LOSS= 0.003955195179786077  ACCURACY= 0.99975\n",
            "EPOCH  9 | EPOCH_TIME= 8.201496  LOSS= 0.003607163972431599  ACCURACY= 0.99985\n",
            "EPOCH  10 | EPOCH_TIME= 8.485679  LOSS= 0.003388421267508071  ACCURACY= 0.99985\n",
            "EPOCH  11 | EPOCH_TIME= 8.303163  LOSS= 0.003122917424370923  ACCURACY= 0.9999\n",
            "EPOCH  12 | EPOCH_TIME= 8.742579  LOSS= 0.002919486146000443  ACCURACY= 0.9999166666666667\n",
            "EPOCH  13 | EPOCH_TIME= 8.440503  LOSS= 0.0027546766257792294  ACCURACY= 0.99995\n",
            "EPOCH  14 | EPOCH_TIME= 8.608999  LOSS= 0.0025737084487127233  ACCURACY= 0.9999833333333333\n",
            "EPOCH  15 | EPOCH_TIME= 8.204964  LOSS= 0.0024485710342906333  ACCURACY= 1.0\n",
            "EPOCH  16 | EPOCH_TIME= 7.992721  LOSS= 0.0022907193216344635  ACCURACY= 1.0\n",
            "EPOCH  17 | EPOCH_TIME= 8.514088  LOSS= 0.002192206747347367  ACCURACY= 1.0\n",
            "EPOCH  18 | EPOCH_TIME= 8.49173  LOSS= 0.002077945537322744  ACCURACY= 1.0\n",
            "EPOCH  19 | EPOCH_TIME= 8.143385  LOSS= 0.0019653247831038405  ACCURACY= 1.0\n",
            "EPOCH  20 | EPOCH_TIME= 8.599355  LOSS= 0.0018765001340024696  ACCURACY= 1.0\n",
            "SUMMARY_TIME= 195.479408  s\n",
            "------- Network test -------\n",
            "LOSS= 0.06577898258062782  ACCURACY = 0.9826\n"
          ]
        }
      ]
    }
  ]
}