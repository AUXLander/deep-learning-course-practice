{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.special import softmax as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file):\n",
    "    with gzip.open(file, 'r') as f:\n",
    "        _ = int.from_bytes(f.read(4), 'big')\n",
    "        image_count = int.from_bytes(f.read(4), 'big')\n",
    "        row_count = int.from_bytes(f.read(4), 'big')\n",
    "        column_count = int.from_bytes(f.read(4), 'big')\n",
    "        image_data = f.read()\n",
    "\n",
    "        return np.frombuffer(image_data, dtype=np.uint8).reshape((image_count, row_count, column_count))\n",
    "\n",
    "def load_labels(file):\n",
    "    with gzip.open(file, 'r') as f:\n",
    "        _ = int.from_bytes(f.read(4), 'big')\n",
    "        _ = int.from_bytes(f.read(4), 'big')\n",
    "        label_data = f.read()\n",
    "        return np.frombuffer(label_data, dtype=np.uint8)\n",
    "\n",
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_LAYER = 10\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train: x - (60000, 28, 28), y - (60000,)\n",
      "shape train: x - (10000, 28, 28), y - (10000,)\n",
      "train: min 0.0, max 1.0\n",
      "test:  min 0.0, max 1.0\n",
      "shape train: x - (60000, 784), y - (60000, 10)\n",
      "shape train: x - (10000, 784), y - (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = load_images('train-images-idx3-ubyte.gz')\n",
    "y_train = load_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "x_test = load_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = load_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "print(f\"shape train: x - {x_train.shape}, y - {y_train.shape}\")\n",
    "print(f\"shape train: x - {x_test.shape}, y - {y_test.shape}\")\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(f\"train: min {x_train.min()}, max {x_train.max()}\")\n",
    "print(f\"test:  min {x_test.min()}, max {x_test.max()}\")\n",
    "\n",
    "y_train = one_hot(y_train, NUM_CLASSES)\n",
    "y_test = one_hot(y_test, NUM_CLASSES)\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
    "\n",
    "print(f\"shape train: x - {x_train.shape}, y - {y_train.shape}\")\n",
    "print(f\"shape train: x - {x_test.shape}, y - {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class FCNN(object):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "        self.w = [np.random.normal(0, np.sqrt(2 / input_layer), (input_layer, hidden_layer)),\n",
    "                  np.random.normal(0, np.sqrt(2 / (input_layer + output_layer)), (hidden_layer, output_layer))]\n",
    "\n",
    "        self.b = [np.full(hidden_layer, 0.05),\n",
    "                  np.full(output_layer, 0.05)]\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return sf(x, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative_relu(x):\n",
    "        return np.where(x > 0.0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        return np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_true, y_pred):\n",
    "        return np.mean(-np.sum(y_true * np.log(y_pred), axis=1))\n",
    "\n",
    "    def __forward(self, x):\n",
    "        x = np.matmul(x, self.w[0]) + self.b[0]\n",
    "        self.t = x.copy()\n",
    "        x = self.relu(x)\n",
    "        self.h = x.copy()\n",
    "\n",
    "        x = np.matmul(x, self.w[1]) + self.b[1]\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def __backward(self, x_train, y_pred, y_true):\n",
    "        mc = 1 / x_train.shape[0]\n",
    "        dz1 = y_pred - y_true\n",
    "\n",
    "        dw1 = mc * np.matmul(self.h.T, dz1)\n",
    "        db1 = mc * np.sum(dz1, axis=0)\n",
    "\n",
    "        dz0 = np.matmul(dz1, self.w[1].T) * self.derivative_relu(self.t)\n",
    "\n",
    "        dw0 = mc * np.matmul(x_train.T, dz0)\n",
    "        db0 = mc * np.sum(dz0, axis=0)\n",
    "\n",
    "        self.w[1] = self.w[1] - self.lr * dw1\n",
    "        self.b[1] = self.b[1] - self.lr * db1\n",
    "\n",
    "        self.w[0] = self.w[0] - self.lr * dw0\n",
    "        self.b[0] = self.b[0] - self.lr * db0\n",
    "\n",
    "    def train(self, x_train, y_train, validation_data=None, epochs=10, learning_rate=0.1, batch_size=32):\n",
    "        self.lr = learning_rate\n",
    "        all_time = datetime.now()\n",
    "        for epoch in range(epochs):\n",
    "            start_time = datetime.now()\n",
    "            for i in range(x_train.shape[0] // batch_size + np.sign(x_train.shape[0] % batch_size)):\n",
    "                st = i * batch_size\n",
    "                ed = min((i + 1) * batch_size, y_train.shape[0])\n",
    "\n",
    "                y_pred = self.__forward(x_train[st:ed])\n",
    "                self.__backward(x_train[st:ed], y_pred, y_train[st:ed])\n",
    "\n",
    "            rtime = (datetime.now() - start_time).total_seconds()\n",
    "            y_pred = self.__forward(x_train)\n",
    "            rloss = self.cross_entropy_loss(y_train, y_pred)\n",
    "            rmetric = self.accuracy(y_train, y_pred)\n",
    "\n",
    "            print(f\"epoch: {epoch+1: >2}, time: {rtime:.3f} sec, train loss: {rloss:.3f}, train accuracy: {rmetric:.3f} \")\n",
    "\n",
    "        print(f\"all train time: {(datetime.now()-all_time).total_seconds():.3f} sec\")\n",
    "            \n",
    "        y_pred = self.__forward(validation_data[0])\n",
    "        rloss = self.cross_entropy_loss(validation_data[1], y_pred)\n",
    "        rmetric = self.accuracy(validation_data[1], y_pred)\n",
    "\n",
    "        print()\n",
    "        print(f\"test loss: {rloss:.3f}, test accuracy: {rmetric:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, time: 3.065 sec, train loss: 0.248, train accuracy: 0.926 \n",
      "epoch:  2, time: 3.159 sec, train loss: 0.175, train accuracy: 0.949 \n",
      "epoch:  3, time: 3.202 sec, train loss: 0.134, train accuracy: 0.961 \n",
      "epoch:  4, time: 3.225 sec, train loss: 0.108, train accuracy: 0.969 \n",
      "epoch:  5, time: 3.893 sec, train loss: 0.091, train accuracy: 0.974 \n",
      "epoch:  6, time: 3.234 sec, train loss: 0.078, train accuracy: 0.978 \n",
      "epoch:  7, time: 3.492 sec, train loss: 0.068, train accuracy: 0.981 \n",
      "epoch:  8, time: 5.228 sec, train loss: 0.061, train accuracy: 0.983 \n",
      "epoch:  9, time: 3.821 sec, train loss: 0.055, train accuracy: 0.985 \n",
      "epoch: 10, time: 3.661 sec, train loss: 0.049, train accuracy: 0.987 \n",
      "epoch: 11, time: 3.814 sec, train loss: 0.045, train accuracy: 0.988 \n",
      "epoch: 12, time: 3.529 sec, train loss: 0.041, train accuracy: 0.989 \n",
      "epoch: 13, time: 3.590 sec, train loss: 0.037, train accuracy: 0.990 \n",
      "epoch: 14, time: 3.526 sec, train loss: 0.034, train accuracy: 0.991 \n",
      "epoch: 15, time: 3.751 sec, train loss: 0.031, train accuracy: 0.992 \n",
      "epoch: 16, time: 4.100 sec, train loss: 0.029, train accuracy: 0.993 \n",
      "epoch: 17, time: 3.501 sec, train loss: 0.027, train accuracy: 0.994 \n",
      "epoch: 18, time: 3.464 sec, train loss: 0.025, train accuracy: 0.994 \n",
      "epoch: 19, time: 4.283 sec, train loss: 0.023, train accuracy: 0.995 \n",
      "epoch: 20, time: 4.370 sec, train loss: 0.022, train accuracy: 0.995 \n",
      "all train time: 85.456 sec\n",
      "\n",
      "test loss: 0.068, test accuracy: 0.979 \n"
     ]
    }
   ],
   "source": [
    "HIDDEN_LAYER = 300\n",
    "LR = 0.1\n",
    "NUMBER_EPOCH = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "fcnn = FCNN(input_layer=x_train.shape[1], hidden_layer=HIDDEN_LAYER, output_layer=OUTPUT_LAYER)\n",
    "fcnn.train(x_train[:], y_train[:], validation_data=(x_test, y_test),\n",
    "           epochs=NUMBER_EPOCH, learning_rate=LR, batch_size=BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
