{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "x_train = idx2numpy.convert_from_file('train-images.idx3-ubyte') / 255\n",
    "y_train = idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "x_test = idx2numpy.convert_from_file('t10k-images.idx3-ubyte') / 255\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')\n",
    "\n",
    "y_train = np.eye(10)[y_train] # convert to one-hot\n",
    "y_test = np.eye(10)[y_test] # convert to one-hot\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(x, y):\n",
    "    return np.mean(-np.sum(x * np.log(y), axis=1))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp/np.sum(exp, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, num_nodes_in_layers):\n",
    "        # weights\n",
    "        self.w1 = np.random.normal(0, 1, [num_nodes_in_layers[0], num_nodes_in_layers[1]])\n",
    "        self.w2 = np.random.normal(0, 1, [num_nodes_in_layers[1], num_nodes_in_layers[2]])\n",
    "\n",
    "        # biases\n",
    "        self.b1 = np.zeros((1, num_nodes_in_layers[1]))\n",
    "        self.b2 = np.zeros((1, num_nodes_in_layers[2]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "\n",
    "        return softmax(self.z2)\n",
    "\n",
    "\n",
    "    def backward_pass(self, out, y_train):\n",
    "        self.delta_y = (out - y_train) / y_train.shape[0]\n",
    "        self.dz0 = np.dot(self.delta_y, self.w2.T)\n",
    "        self.dz0 * np.where(self.z1 > 0.0, 1, 0) # derivative of relu\n",
    "\n",
    "    def backpropagation(self, x_train, learning_rate):\n",
    "        dw2 = np.dot(self.a1.T, self.delta_y)\n",
    "        db2 = np.sum(self.delta_y, axis=0)\n",
    "\n",
    "        dw1 = np.dot(x_train.T, self.dz0)\n",
    "        db1 = np.sum(self.dz0, axis=0)\n",
    "\n",
    "        # ipdate weights\n",
    "        self.w1 = self.w1 - learning_rate * dw1\n",
    "        self.w2 = self.w2 - learning_rate * dw2\n",
    "\n",
    "        # update biases\n",
    "        self.b1 = self.b1 - learning_rate * db1\n",
    "        self.b2 = self.b2 - learning_rate * db2\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, epochs=20, learning_rate=0.1, batch_size=64):\n",
    "        start_train = datetime.now()\n",
    "        for epoch in range(epochs):\n",
    "            start_time = datetime.now()\n",
    "            iteration = 0\n",
    "            while iteration < len(x_train):\n",
    "                x_batch = x_train[iteration:iteration + batch_size]\n",
    "                y_batch = y_train[iteration:iteration + batch_size]\n",
    "\n",
    "                y = self.forward(x_batch)\n",
    "\n",
    "                self.backward_pass(y, y_batch)\n",
    "                self.backpropagation(x_batch, learning_rate)\n",
    "                iteration += batch_size\n",
    "\n",
    "            time = (datetime.now() - start_time).total_seconds()\n",
    "            out = self.forward(x_train)\n",
    "            cross_entropy = cross_entropy_loss(y_train, out)\n",
    "            accuracy = np.mean(np.argmax(y_train, axis=1) == np.argmax(out, axis=1))\n",
    "\n",
    "            print(\n",
    "                f'Epoch[{epoch + 1}]    Time: {time:.2f} s\\t\\tcross-entropy-error: {cross_entropy:.3f}\\t\\taccuracy: {accuracy:.3f}')\n",
    "\n",
    "        finish_train = datetime.now()\n",
    "        print(f\"Train time: {(finish_train - start_train).total_seconds():.2f} s\\n\"\n",
    "              f\"Train error: {cross_entropy:.3f}\\n\"\n",
    "              f\"Train accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "    def test(self, x_test, y_test):\n",
    "        out = self.forward(x_test)\n",
    "        cross_entropy = cross_entropy_loss(y_test, out)\n",
    "        accuracy = np.mean(np.argmax(y_test, axis=1) == np.argmax(out, axis=1))\n",
    "\n",
    "        print()\n",
    "        print(f\"Test error: {cross_entropy:.3f}\\nTest accuracy: {accuracy:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]    Time: 4.47 s\t\tcross-entropy-error: 2.011\t\taccuracy: 0.916\n",
      "Epoch[2]    Time: 4.55 s\t\tcross-entropy-error: 1.006\t\taccuracy: 0.939\n",
      "Epoch[3]    Time: 4.21 s\t\tcross-entropy-error: 0.716\t\taccuracy: 0.947\n",
      "Epoch[4]    Time: 4.10 s\t\tcross-entropy-error: 0.514\t\taccuracy: 0.955\n",
      "Epoch[5]    Time: 4.15 s\t\tcross-entropy-error: 0.417\t\taccuracy: 0.958\n",
      "Epoch[6]    Time: 4.15 s\t\tcross-entropy-error: 0.347\t\taccuracy: 0.962\n",
      "Epoch[7]    Time: 4.18 s\t\tcross-entropy-error: 0.304\t\taccuracy: 0.963\n",
      "Epoch[8]    Time: 4.40 s\t\tcross-entropy-error: 0.244\t\taccuracy: 0.968\n",
      "Epoch[9]    Time: 4.86 s\t\tcross-entropy-error: 0.211\t\taccuracy: 0.970\n",
      "Epoch[10]    Time: 4.76 s\t\tcross-entropy-error: 0.183\t\taccuracy: 0.972\n",
      "Epoch[11]    Time: 4.58 s\t\tcross-entropy-error: 0.170\t\taccuracy: 0.973\n",
      "Epoch[12]    Time: 4.36 s\t\tcross-entropy-error: 0.139\t\taccuracy: 0.976\n",
      "Epoch[13]    Time: 4.18 s\t\tcross-entropy-error: 0.134\t\taccuracy: 0.976\n",
      "Epoch[14]    Time: 4.27 s\t\tcross-entropy-error: 0.130\t\taccuracy: 0.976\n",
      "Epoch[15]    Time: 4.56 s\t\tcross-entropy-error: 0.113\t\taccuracy: 0.977\n",
      "Epoch[16]    Time: 4.32 s\t\tcross-entropy-error: 0.099\t\taccuracy: 0.979\n",
      "Epoch[17]    Time: 4.21 s\t\tcross-entropy-error: 0.094\t\taccuracy: 0.979\n",
      "Epoch[18]    Time: 4.26 s\t\tcross-entropy-error: 0.096\t\taccuracy: 0.978\n",
      "Epoch[19]    Time: 4.17 s\t\tcross-entropy-error: 0.079\t\taccuracy: 0.982\n",
      "Epoch[20]    Time: 4.29 s\t\tcross-entropy-error: 0.076\t\taccuracy: 0.982\n",
      "Train time: 99.86 s\n",
      "Train error: 0.076\n",
      "Train accuracy: 0.98\n",
      "\n",
      "Test error: 0.605\n",
      "Test accuracy: 0.95 \n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([784, 300, 10])\n",
    "nn.train(x_train, y_train)\n",
    "nn.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
