{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "x_train = idx2numpy.convert_from_file('train-images.idx3-ubyte') / 255\n",
    "y_train = idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "x_test = idx2numpy.convert_from_file('t10k-images.idx3-ubyte') / 255\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')\n",
    "\n",
    "y_train = np.eye(10)[y_train] # convert to one-hot\n",
    "y_test = np.eye(10)[y_test] # convert to one-hot\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(x, y):\n",
    "    return np.mean(-np.sum(x * np.log(y), axis=1))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp/np.sum(exp, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, num_nodes_in_layers):\n",
    "        # weights\n",
    "        self.w1 = np.random.normal(0, np.sqrt(2 / num_nodes_in_layers[0]), [num_nodes_in_layers[0], num_nodes_in_layers[1]])\n",
    "        self.w2 = np.random.normal(0, np.sqrt(2 / num_nodes_in_layers[1]), [num_nodes_in_layers[1], num_nodes_in_layers[2]])\n",
    "\n",
    "        # biases\n",
    "        self.b1 = np.zeros((1, num_nodes_in_layers[1]))\n",
    "        self.b2 = np.zeros((1, num_nodes_in_layers[2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = softmax(self.z2)\n",
    "\n",
    "    def backpropagation(self, xTrain, yTrain, learningRate):\n",
    "        dz2 = (self.a2 - yTrain) / self.a2.shape[0]\n",
    "        dw1 = (self.a1.T).dot(dz2)\n",
    "        db1 = np.sum(dz2, axis=0, keepdims=True)\n",
    "        dz1 = dz2.dot(self.w2.T) * np.where(self.z1 > 0.0, 1, 0)\n",
    "        dw0 = np.dot(xTrain.T, dz1)\n",
    "        db0 = np.sum(dz1, axis=0, keepdims=True)\n",
    "        \n",
    "        # ipdate weights\n",
    "        self.w2 -= learningRate * dw1\n",
    "        self.w1 -= learningRate * dw0\n",
    "        \n",
    "        # update biases\n",
    "        self.b2 -= learningRate * db1\n",
    "        self.b1 -= learningRate * db0\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, epochs=20, learning_rate=0.1, batch_size=64):\n",
    "        start_train = datetime.now()\n",
    "        for epoch in range(epochs):\n",
    "            start_time = datetime.now()\n",
    "            iteration = 0\n",
    "            while iteration < len(x_train):\n",
    "                x_batch = x_train[iteration:iteration + batch_size]\n",
    "                y_batch = y_train[iteration:iteration + batch_size]\n",
    "\n",
    "                y = self.forward(x_batch)\n",
    "                self.backpropagation(x_batch, y_batch, learning_rate)\n",
    "                iteration += batch_size\n",
    "\n",
    "            time = (datetime.now() - start_time).total_seconds()\n",
    "            out = self.forward(x_train)\n",
    "            cross_entropy = cross_entropy_loss(y_train, self.a2)\n",
    "            accuracy = np.mean(np.argmax(y_train, axis=1) == np.argmax(self.a2, axis=1))\n",
    "\n",
    "            print(\n",
    "                f'Epoch[{epoch + 1}]    Time: {time:.2f} s\\t\\tcross-entropy-error: {cross_entropy:.3f}\\t\\taccuracy: {accuracy:.3f}')\n",
    "\n",
    "        finish_train = datetime.now()\n",
    "        print(f\"Train time: {(finish_train - start_train).total_seconds():.2f} s\\n\"\n",
    "              f\"Train error: {cross_entropy:.3f}\\n\"\n",
    "              f\"Train accuracy: {accuracy:.3f}\")\n",
    "\n",
    "\n",
    "    def test(self, x_test, y_test):\n",
    "        out = self.forward(x_test)\n",
    "        cross_entropy = cross_entropy_loss(y_test, self.a2)\n",
    "        accuracy = np.mean(np.argmax(y_test, axis=1) == np.argmax(self.a2, axis=1))\n",
    "\n",
    "        print()\n",
    "        print(f\"Test error: {cross_entropy:.3f}\\nTest accuracy: {accuracy:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]    Time: 18.77 s\t\tcross-entropy-error: 0.224\t\taccuracy: 0.934\n",
      "Epoch[2]    Time: 2.82 s\t\tcross-entropy-error: 0.157\t\taccuracy: 0.954\n",
      "Epoch[3]    Time: 2.89 s\t\tcross-entropy-error: 0.122\t\taccuracy: 0.965\n",
      "Epoch[4]    Time: 2.88 s\t\tcross-entropy-error: 0.100\t\taccuracy: 0.971\n",
      "Epoch[5]    Time: 2.63 s\t\tcross-entropy-error: 0.084\t\taccuracy: 0.977\n",
      "Epoch[6]    Time: 2.89 s\t\tcross-entropy-error: 0.072\t\taccuracy: 0.980\n",
      "Epoch[7]    Time: 2.61 s\t\tcross-entropy-error: 0.062\t\taccuracy: 0.983\n",
      "Epoch[8]    Time: 2.60 s\t\tcross-entropy-error: 0.055\t\taccuracy: 0.985\n",
      "Epoch[9]    Time: 2.61 s\t\tcross-entropy-error: 0.049\t\taccuracy: 0.987\n",
      "Epoch[10]    Time: 2.71 s\t\tcross-entropy-error: 0.044\t\taccuracy: 0.988\n",
      "Epoch[11]    Time: 2.64 s\t\tcross-entropy-error: 0.040\t\taccuracy: 0.989\n",
      "Epoch[12]    Time: 2.60 s\t\tcross-entropy-error: 0.037\t\taccuracy: 0.991\n",
      "Epoch[13]    Time: 2.62 s\t\tcross-entropy-error: 0.034\t\taccuracy: 0.991\n",
      "Epoch[14]    Time: 2.61 s\t\tcross-entropy-error: 0.031\t\taccuracy: 0.992\n",
      "Epoch[15]    Time: 2.61 s\t\tcross-entropy-error: 0.028\t\taccuracy: 0.993\n",
      "Epoch[16]    Time: 2.86 s\t\tcross-entropy-error: 0.026\t\taccuracy: 0.994\n",
      "Epoch[17]    Time: 2.59 s\t\tcross-entropy-error: 0.024\t\taccuracy: 0.994\n",
      "Epoch[18]    Time: 2.62 s\t\tcross-entropy-error: 0.023\t\taccuracy: 0.995\n",
      "Epoch[19]    Time: 2.64 s\t\tcross-entropy-error: 0.021\t\taccuracy: 0.996\n",
      "Epoch[20]    Time: 2.63 s\t\tcross-entropy-error: 0.019\t\taccuracy: 0.996\n",
      "Train time: 80.77 s\n",
      "Train error: 0.019\n",
      "Train accuracy: 0.996\n",
      "\n",
      "Test error: 0.067\n",
      "Test accuracy: 0.980 \n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([784, 300, 10])\n",
    "nn.train(x_train, y_train)\n",
    "nn.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
