# Репозиторий для публикации результатов выполнения лабораторных работ по курсу "Глубокое обучение"

## Цели
Цель настоящей работы состоит в том, чтобы изучить метод обратного распространения ошибки для обучения глубоких нейронных сетей на примере двухслойной полностью связанной сети (один скрытый слой). 

## Задачи
Выполнение практической работы предполагает решение следующих задач:

- Изучение общей схемы метода обратного распространения ошибки.
- Вывод математических формул для вычисления градиентов функции ошибки по параметрам нейронной сети и формул коррекции весов.
- Проектирование и разработка программной реализации.
- Тестирование разработанной программной реализации.

В процессе выполнения лабораторной работы предполагается, что сеть ориентирована на решение задачи классификации одноканальных изображений. Типичным примером такой задачи является задача классификации рукописных цифр. Именно ее предлагается использовать в качестве тестовой задачи на примере набора данных MNIST [http://yann.lecun.com/exdb/mnist]. 

Метод обратного распространения ошибки разрабатывается, исходя из следующих предположений:

1. На входе сети имеется w×h нейронов, что соответствует разрешению изображения.
1. На выходе сети имеется k нейронов, что соответствует количеству классов изображений.
1. Скрытый слой содержит s нейронов.
1. В качестве функции активации на скрытом слое используется функция ReLU.
1. В качестве функции активации на втором слое используется функция softmax.
1. В качестве функции ошибки используется кросс-энтропия.
1. Реализуется стохастический градиентный спуск (скорость обучения и количество эпох – параметры метода).

## Требования к результатам выполнения работы

Условия успешной сдачи лабораторной работы:
1. Разработана программная реализация метода для рассматриваемого частного случая нейронной сети и приложение для решения задачи классификации рукописных цифр на примере базы MNIST на языке Python 3 (например, в Jupiter Notebook). В результате сформирован скрипт в формате `.ipynb` с выдачей промежуточных результатов. Скрипт должен отображать ошибку классификации на тренировочном наборе данных в процессе обучения по окончании каждой эпохи. По завершении всех эпох скрипт должен выдать ошибку классификации на тестовом наборе данных.
2. Разработанный скрипт сконвертирован в формат `.html` внутренними средствами среды разработки. Сконвертированный скрипт должен содержать полученные при его запуске результаты.
3. Подготовлен текстовый файл в формате Markdown (README.md), в котором приведена в виде таблички информация о результатах решения задачи классификации рукописных цифр на наборе данных MNIST: ФИО студента, количество нейронов на скрытом слое, скорость обучения модели, количество эпох, ошибка классификации на тренировочном наборе данных, ошибка классификации на тестовом наборе данных.

| ФИО | Hidden neurons| Learning rate | Number of epochs | Train accuracy | Test accuracy |
|-|-|-|-|-|-|
| Иванов Иван Иванович | 200 | 0.1 | 10 | 0.98 | 0.92 |

4. Скрипт в формате `.ipynb`, его сконвертированная копия в формате `.html` выложены репозиторий на GitHub [https://github.com/UNN-ITMM-Software/deep-learning-course-practice]. При этом все файлы должны находиться в директории с названием FamiliaIO (например, `IvanovII`).
